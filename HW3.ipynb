{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Homework 3}$\n",
    "\n",
    "$\\textbf{Problem #1}$\n",
    "\n",
    "We're going to briefly look at truth tables. As an example let's assume we have a 100 photos, some of birds and some of people. In a truth table you assume you can categorize the true answerâ€”let's say you pay an undergraduate to sort the photos into birds and people. Then you want to have an automated sorting algorithm. However that works, whether it is by looking a the color at the center of photo or using a neural network (NN), it will also sort the photos but imperfectly. Given two sorts you can then arrange a truth table:\n",
    "\n",
    "|           | True Bird | True Person |\n",
    "|-----------|-----------|-------------|\n",
    "| NN Bird   | 45        | 5           |\n",
    "| NN Person | 3         | 47          |\n",
    "\n",
    "\n",
    "There are 48 birds and 52 People (columns), and there are 8 miscategorizations. The NN called three of the birds people, and 5 of the people birds.\n",
    "\n",
    "This is useful because it not only shows the number of errors, but the type, and not all errors are created equal. Let's say our identification system is being used to keep birds from escaping the aviary at the zoo by locking the aviary door when a bird is trying to escape. We really don't want to let birds escape, but locking a person in for 30 extra seconds is not a big deal. In this case false bird identification is not so bad, but false person identification lets a bird escape.\n",
    "\n",
    "Let's say the above truth table is the current system, and you've developed a new algorithm (NA) with the following truth table:\n",
    "\n",
    "|           | True Bird | True Person |\n",
    "|-----------|-----------|-------------|\n",
    "| NA Bird   | 47        | 11          |\n",
    "| NA Person | 1         | 42          |\n",
    "\n",
    "\n",
    "1a) Which algorithm makes the fewest mistakes?\n",
    "\n",
    "The NN algorithm makes the fewest mistakes, as it mistakes 3 birds for people, and 5 people for birds for a total of 8 mistakes. The NA algorithm however mistook 1 bird for a person, and 11 people for birds for a total of 12 mistakes. \n",
    "\n",
    "1b) Which algorithm is better for the zoo? Explain.\n",
    "\n",
    "For the zue, the NA algorithm should end up working better, since the identification system is used to stop birds from escaping. Since the NN algorithm mistook 3 birds for people but the NA algorithm only mistook 1 bird for a person, fewer birds would have potentially escaped with the NA algorithm.\n",
    "\n",
    "1c) During the pandemic the number of visitors plummets, and it is only the zoo keeper visiting. So instead of 52% of the photos taken at the aviary door being people, it is now only 1%. Make new truth tables for both algorithms.\n",
    "\n",
    "Since the NN system accurately detects 45/48 birds, it's success rate across 99 birds should be approximately that same ratio. Since $\\frac{45}{48} \\approx 0.9375$, it follows that for 99 birds, $0.9375 * 99 \\approx 92.8125 \\approx 93$ would be properly identified out of 99.\n",
    "\n",
    "|           | True Bird | True Person |\n",
    "|-----------|-----------|-------------|\n",
    "| NN Bird   | 93        | 0           |\n",
    "| NN Person | 6         | 1           |\n",
    "\n",
    "The NA system accurately picks 47/48 birds, so with the same process as above that means for a bird sample size of 99, it should detect $\\frac{47}{48} * 99 \\approx 96.9375 \\approx 97$\n",
    "\n",
    "|           | True Bird | True Person |\n",
    "|-----------|-----------|-------------|\n",
    "| NA Bird   | 97        | 0           |\n",
    "| NA Person | 2         | 1           |\n",
    "\n",
    "$\\textbf{Problem #2}$\n",
    "In the last lab we explored how to numerically calculate the pdf of a summed or averaged observation through repeated convolutions. But sometimes the convolution has an analytical solution. We could have found this out by either using a sharp pencil and doing the convolution integral by hand, or by looking it up in a table (much easier).\n",
    "\n",
    "Having an analytic answer is much nicer when they exist, so it is always good to look and see if it exists. Further, sums and averages are only some of the mathematical operations that we can perform. In this section we will do an internet scavenger hunt to find the analytic pdf for some interesting distributions.\n",
    "\n",
    "$\\textbf{Example #1}$\n",
    "What is the sum of two Guassian distributions?\n",
    "\n",
    "We did this numerically in the last lab, but we can find it analytically. One might start with this page on the normal distribution which would refer you to this page on the sum, which would give you the same answer you figured out last week.\n",
    "\n",
    "$\\textbf{Example #2}$\n",
    "Let's say we have a variable with a Rayleigh distribution, and we're going to square it. What is the distribution?\n",
    "\n",
    "First I'll lookup and read about the Rayleigh distribution, such as this Wikipedia page (Mathworld and other sources, such as CRC books are great too). Down near the bottom are listed a number of related distributions. Note that the square of the Rayleigh is listed as a gamma distribution with N = 1. Looking up the gamma distribution we see that a gamma with N=1 is an exponential distribution, and just to check we can see that the sqrt of an exponential distribution is a Rayleigh distribution to bring us full circle.\n",
    "\n",
    "Now it is your turn!\n",
    "\n",
    "2a) What is the pdf of the sum of two identical exponential distributions?\n",
    "\n",
    "The exponential distribution can be described by the probability density function $ f(x;\\lambda) = \\begin{cases}\\lambda e^{-\\lambda x} & x \\ge 0, \\\\0 & x < 0.\\end{cases}$, where $\\lambda > 0$ is denoted as the rate parameter. The sum of two exponential probability density functions $Z = X_1 + X_2$ is as follows:\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}f_{Z}(z)&=\\int _{-\\infty }^{\\infty }f_{X_{1}}(x_{1})f_{X_{2}}(z-x_{1})\\,dx_{1}\\\\&=\\int _{0}^{z}\\lambda _{1}e^{-\\lambda _{1}x_{1}}\\lambda _{2}e^{-\\lambda _{2}(z-x_{1})}\\,dx_{1}\\\\&=\\lambda _{1}\\lambda _{2}e^{-\\lambda _{2}z}\\int _{0}^{z}e^{(\\lambda _{2}-\\lambda _{1})x_{1}}\\,dx_{1}\\\\&={\\begin{cases}{\\dfrac {\\lambda _{1}\\lambda _{2}}{\\lambda _{2}-\\lambda _{1}}}\\left(e^{-\\lambda _{1}z}-e^{-\\lambda _{2}z}\\right)&{\\text{ if }}\\lambda _{1}\\neq \\lambda _{2}\\\\[4pt]\\lambda ^{2}ze^{-\\lambda z}&{\\text{ if }}\\lambda _{1}=\\lambda _{2}=\\lambda .\\end{cases}}\\end{aligned}}}$\n",
    "\n",
    "Now, since we are interested in the sum for of two identicial exponential distributions, it is clear that they must have identical rate parameters, i.e $\\lambda _1 = \\lambda _ 2 = \\lambda$\n",
    "This leads to the conclusion that the pdf for the sum of two identical exponential distributions is simply $f(x;\\lambda) = \\lambda ^2 x e^{-\\lambda x}$, which is an Erlang distribution with shape 2 and parameter $\\lambda$, which is itself a special case of the gamma distribution.\n",
    "\n",
    "An Erlang distribution has a probability density function of $f(x;k,\\lambda )={\\lambda ^{k}x^{{k-1}}e^{{-\\lambda x}} \\over (k-1)!}\\quad {\\mbox{for }}x,\\lambda \\geq 0,$, so it is evident that for $k = 2, f(x;\\lambda) = \\lambda ^2 x e^{-\\lambda x}$ which is consistent with the distribution for two identical exponential distributions.\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Exponential_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Erlang_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gamma_distribution\n",
    "\n",
    "2b) What is the pdf of the ratio of two zero-mean unity variance normal distributions $X_1/X_2$?\n",
    "\n",
    "If you take the ratio between two independent standard normal random variables with mean 0 and wariance 1, their ratio follows the standard Cauchy distribution ${\\displaystyle X_{1}/X_{2}\\sim \\operatorname {Cauchy} (0,1)}$\n",
    "\n",
    "The Cauchy distribution follows the probability density function $f(x;x_{0},\\gamma )={\\frac  {1}{\\pi \\gamma \\left[1+\\left({\\frac  {x-x_{0}}{\\gamma }}\\right)^{2}\\right]}}={1 \\over \\pi \\gamma }\\left[{\\gamma ^{2} \\over (x-x_{0})^{2}+\\gamma ^{2}}\\right],$ where $\\text{Cauchy}(0, 1)$ = $f(x; 0,1) = \\frac{1}{\\pi (1 + x^2)}$\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Normal_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cauchy_distribution\n",
    "\n",
    "2c) So far we have looked at 1D probability distributions, but it is possible to have a multi-dimensional vector distribution. A simple first introduction is the 2D Guassian; it looks like a smeared spot. Mathematically this is given by $X \\hat{i} + Y \\hat{j}$ where both $X$ and $Y$ are drawn from 1D Gaussian distributions. If I measure the amplitude of this vector, what is its pdf? (Hint, the amplitude is always positive.)\n",
    "\n",
    "We see in the definition of the standard normal distribution that for the combination of two independent random variables, their Euclidean norm $\\sqrt{X_1^2 + X_2^2}$ is described by the Rayleigh distribution $f(x;\\sigma )={\\frac {x}{\\sigma ^{2}}}e^{-x^{2}/(2\\sigma ^{2})},\\quad x\\geq 0,$\n",
    "\n",
    "Now, in the easiest multi-dimensional case (2D), we can treat $X \\hat{i} + Y \\hat{j}$ as a multidemnsional vector. The following proof is found fully written on the wikipedia page, but I'll re-transcribe it here for simplicity's sake. Instead of $X \\hat{i} + Y \\hat{j}$, we'll define $Y = (U,V) = X \\hat{i} + Y \\hat{j} = (X,Y)$\n",
    "\n",
    "Now, $U$ and $V$ have density functions ${\\displaystyle f_{U}(x;\\sigma )=f_{V}(x;\\sigma )={\\frac {e^{-x^{2}/(2\\sigma ^{2})}}{\\sqrt {2\\pi \\sigma ^{2}}}}}$\n",
    "\n",
    "We then let $X$ be defined as the amplitude of $Y$, i.e $X = \\sqrt{U^2 +V^2}$. It follows that $X$ has the cumulative distribution function ${\\displaystyle F_{X}(x;\\sigma )=\\iint _{D_{x}}f_{U}(u;\\sigma )f_{V}(v;\\sigma )\\,dA,}$, where ${\\displaystyle D_{x}=\\left\\{(u,v):{\\sqrt {u^{2}+v^{2}}}<x\\right\\}}$. \n",
    "\n",
    "This integral is more easily calculated in polar coordinates, so after a conversion it follows that ${\\displaystyle F_{X}(x;\\sigma )={\\frac {1}{2\\pi \\sigma ^{2}}}\\int _{0}^{2\\pi }\\int _{0}^{x}re^{-r^{2}/(2\\sigma ^{2})}\\,dr\\,d\\theta ={\\frac {1}{\\sigma ^{2}}}\\int _{0}^{x}re^{-r^{2}/(2\\sigma ^{2})}\\,dr.}$\n",
    "\n",
    "Finally, we take the derivative of the cumulative distribution function is the probability density function, thus ${\\displaystyle f_{X}(x;\\sigma )={\\frac {d}{dx}}F_{X}(x;\\sigma )={\\frac {x}{\\sigma ^{2}}}e^{-x^{2}/(2\\sigma ^{2})},}$ which is the Rayleigh distribution, thus bringing it full circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
